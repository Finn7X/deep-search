"""
æŸ¥è¯¢åˆ†æå’Œæ”¹å†™æ¨¡å—
è´Ÿè´£åˆ†æç”¨æˆ·æŸ¥è¯¢ï¼Œç”Ÿæˆå¤šä¸ªæœç´¢å˜ä½“ï¼Œå¹¶è¯†åˆ«æœç´¢å¤æ‚åº¦
"""

import json
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
from rich.console import Console
from rich.panel import Panel

console = Console()

class QueryComplexity(Enum):
    SIMPLE = "simple"           # å•ä¸€æ¦‚å¿µæŸ¥è¯¢
    MODERATE = "moderate"       # éœ€è¦2-3ä¸ªæ¦‚å¿µç»“åˆ
    COMPLEX = "complex"         # éœ€è¦å¤šä¸ªæ¦‚å¿µå’Œæ¨ç†
    MULTI_HOP = "multi_hop"     # éœ€è¦å¤šæ­¥æ¨ç†å’Œæœç´¢

@dataclass
class QueryAnalysis:
    original_query: str
    complexity: QueryComplexity
    main_concepts: List[str]
    sub_questions: List[str]
    search_variants: List[str]
    requires_multi_hop: bool
    estimated_search_rounds: int
    domain_hints: List[str]
    reasoning: str

class QueryAnalyzer:
    def __init__(self, deepseek_client):
        self.deepseek_client = deepseek_client
        
    def analyze_query(self, query: str) -> QueryAnalysis:
        """
        æ·±åº¦åˆ†æç”¨æˆ·æŸ¥è¯¢ï¼Œè¯†åˆ«å¤æ‚åº¦å’Œæœç´¢ç­–ç•¥
        """
        console.print(Panel(
            f"[bold blue]ğŸ” å¼€å§‹æŸ¥è¯¢åˆ†æ[/bold blue]\n"
            f"[cyan]åŸå§‹æŸ¥è¯¢:[/cyan] {query}",
            title="æŸ¥è¯¢åˆ†æ",
            border_style="blue"
        ))
        
        # æ„å»ºåˆ†ææç¤ºè¯
        analysis_prompt = self._build_analysis_prompt(query)
        
        # è°ƒç”¨AIè¿›è¡Œåˆ†æ
        response = self.deepseek_client.chat_completion(
            messages=[{"role": "user", "content": analysis_prompt}],
            stream=False,
            temperature=0.3
        )
        
        if "error" in response:
            # å¦‚æœAIåˆ†æå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€åˆ†æ
            return self._basic_analysis(query)
        
        try:
            # æ¸…ç†å“åº”å†…å®¹ï¼Œç§»é™¤å¯èƒ½çš„markdownæ ¼å¼
            content = response["content"].strip()
            if content.startswith("```json"):
                content = content[7:]  # ç§»é™¤å¼€å¤´çš„ ```json
            if content.endswith("```"):
                content = content[:-3]  # ç§»é™¤ç»“å°¾çš„ ```
            content = content.strip()
            
            # è§£æAIè¿”å›çš„åˆ†æç»“æœ
            analysis_data = json.loads(content)
            return self._parse_analysis_response(query, analysis_data)
            
        except (json.JSONDecodeError, KeyError) as e:
            console.print(f"[yellow]âš ï¸  AIåˆ†æè§£æå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€åˆ†æ: {e}[/yellow]")
            return self._basic_analysis(query)
    
    def _build_analysis_prompt(self, query: str) -> str:
        """æ„å»ºæŸ¥è¯¢åˆ†ææç¤ºè¯"""
        
        prompt = f"""
è¯·æ·±åº¦åˆ†æä»¥ä¸‹ç”¨æˆ·æŸ¥è¯¢ï¼Œå¹¶è¿”å›JSONæ ¼å¼çš„åˆ†æç»“æœï¼š

ç”¨æˆ·æŸ¥è¯¢: "{query}"

è¯·åˆ†æå¹¶è¿”å›ä»¥ä¸‹ä¿¡æ¯çš„JSONï¼š

{{
    "complexity": "simple/moderate/complex/multi_hop",
    "main_concepts": ["æ¦‚å¿µ1", "æ¦‚å¿µ2", ...],
    "sub_questions": ["å­é—®é¢˜1", "å­é—®é¢˜2", ...],
    "search_variants": ["æœç´¢å˜ä½“1", "æœç´¢å˜ä½“2", ...],
    "requires_multi_hop": true/false,
    "estimated_search_rounds": æ•°å­—,
    "domain_hints": ["å»ºè®®çš„æœç´¢åŸŸå1", "åŸŸå2", ...],
    "reasoning": "åˆ†ææ¨ç†è¿‡ç¨‹çš„è¯¦ç»†è¯´æ˜"
}}

åˆ†ææ ‡å‡†ï¼š
1. complexityåˆ¤æ–­ï¼š
   - simple: å•ä¸€æ˜ç¡®æ¦‚å¿µï¼Œå¦‚"ä»€ä¹ˆæ˜¯Python"
   - moderate: éœ€è¦2-3ä¸ªæ¦‚å¿µç»“åˆï¼Œå¦‚"Pythonä¸Javaçš„åŒºåˆ«" 
   - complex: å¤šæ¦‚å¿µéœ€è¦æ·±åº¦åˆ†æï¼Œå¦‚"æœºå™¨å­¦ä¹ åœ¨é‡‘èé£æ§ä¸­çš„åº”ç”¨"
   - multi_hop: éœ€è¦å¤šæ­¥æ¨ç†ï¼Œå¦‚"GPT-4ç›¸æ¯”GPT-3åœ¨ä»£ç ç”Ÿæˆèƒ½åŠ›ä¸Šçš„æå‡å¦‚ä½•å½±å“ç¨‹åºå‘˜å·¥ä½œ"

2. sub_questions: å°†å¤æ‚æŸ¥è¯¢åˆ†è§£ä¸ºå¯ç‹¬ç«‹æœç´¢çš„å­é—®é¢˜

3. search_variants: ç”Ÿæˆ3-5ä¸ªä¸åŒè§’åº¦çš„æœç´¢å…³é”®è¯ç»„åˆ

4. estimated_search_rounds: é¢„ä¼°éœ€è¦çš„æœç´¢è½®æ¬¡(1-5)

5. domain_hints: å»ºè®®é‡ç‚¹æœç´¢çš„ç½‘ç«™åŸŸå

6. requires_multi_hop: æ˜¯å¦éœ€è¦åŸºäºå‰ä¸€æ¬¡æœç´¢ç»“æœè¿›è¡Œä¸‹ä¸€æ¬¡æœç´¢

è¯·ç¡®ä¿è¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼ã€‚
"""
        return prompt
    
    def _parse_analysis_response(self, query: str, analysis_data: Dict[str, Any]) -> QueryAnalysis:
        """è§£æAIåˆ†æå“åº”"""
        
        try:
            complexity = QueryComplexity(analysis_data.get("complexity", "moderate"))
        except ValueError:
            complexity = QueryComplexity.MODERATE
        
        analysis = QueryAnalysis(
            original_query=query,
            complexity=complexity,
            main_concepts=analysis_data.get("main_concepts", []),
            sub_questions=analysis_data.get("sub_questions", []),
            search_variants=analysis_data.get("search_variants", [query]),
            requires_multi_hop=analysis_data.get("requires_multi_hop", False),
            estimated_search_rounds=min(analysis_data.get("estimated_search_rounds", 1), 5),
            domain_hints=analysis_data.get("domain_hints", []),
            reasoning=analysis_data.get("reasoning", "åŸºäºAIåˆ†æ")
        )
        
        self._log_analysis_result(analysis)
        return analysis
    
    def _basic_analysis(self, query: str) -> QueryAnalysis:
        """åŸºç¡€æŸ¥è¯¢åˆ†æï¼ˆå½“AIåˆ†æå¤±è´¥æ—¶çš„å¤‡é€‰æ–¹æ¡ˆï¼‰"""
        
        # ç®€å•çš„è§„åˆ™åŸºç¡€åˆ†æ
        query_lower = query.lower()
        
        # åˆ¤æ–­å¤æ‚åº¦
        complexity_indicators = {
            "simple": ["ä»€ä¹ˆæ˜¯", "å®šä¹‰", "ä»‹ç»"],
            "moderate": ["æ¯”è¾ƒ", "åŒºåˆ«", "ä¼˜ç¼ºç‚¹", "VS", "å¯¹æ¯”"],
            "complex": ["åº”ç”¨", "å½±å“", "è¶‹åŠ¿", "å‘å±•", "åˆ†æ"],
            "multi_hop": ["å¦‚ä½•å½±å“", "åŸºäº", "å¯¼è‡´", "ä¸ºä»€ä¹ˆä¼š", "æ·±å±‚åŸå› "]
        }
        
        complexity = QueryComplexity.SIMPLE
        for level, indicators in complexity_indicators.items():
            if any(indicator in query for indicator in indicators):
                complexity = QueryComplexity(level)
        
        # ç”Ÿæˆæœç´¢å˜ä½“
        search_variants = [
            query,
            f"{query} è¯¦ç»†è§£é‡Š",
            f"{query} æœ€æ–°å‘å±•"
        ]
        
        analysis = QueryAnalysis(
            original_query=query,
            complexity=complexity,
            main_concepts=query.split()[:3],  # ç®€å•æå–å‰3ä¸ªè¯ä½œä¸ºæ¦‚å¿µ
            sub_questions=[query],
            search_variants=search_variants,
            requires_multi_hop=complexity in [QueryComplexity.COMPLEX, QueryComplexity.MULTI_HOP],
            estimated_search_rounds=1 if complexity == QueryComplexity.SIMPLE else 2,
            domain_hints=[],
            reasoning="åŸºäºè§„åˆ™çš„åŸºç¡€åˆ†æ"
        )
        
        self._log_analysis_result(analysis)
        return analysis
    
    def _log_analysis_result(self, analysis: QueryAnalysis):
        """è®°å½•åˆ†æç»“æœ"""
        
        console.print(Panel(
            f"[bold green]âœ… æŸ¥è¯¢åˆ†æå®Œæˆ[/bold green]\n"
            f"[cyan]å¤æ‚åº¦:[/cyan] {analysis.complexity.value}\n"
            f"[cyan]ä¸»è¦æ¦‚å¿µ:[/cyan] {', '.join(analysis.main_concepts)}\n"
            f"[cyan]éœ€è¦å¤šè·³æœç´¢:[/cyan] {'æ˜¯' if analysis.requires_multi_hop else 'å¦'}\n"
            f"[cyan]é¢„ä¼°æœç´¢è½®æ¬¡:[/cyan] {analysis.estimated_search_rounds}\n"
            f"[cyan]å­é—®é¢˜æ•°é‡:[/cyan] {len(analysis.sub_questions)}\n"
            f"[cyan]æœç´¢å˜ä½“æ•°é‡:[/cyan] {len(analysis.search_variants)}",
            title="åˆ†æç»“æœ",
            border_style="green"
        ))
        
        if analysis.sub_questions:
            console.print(Panel(
                "\n".join([f"â€¢ {q}" for q in analysis.sub_questions]),
                title="ğŸ¯ å­é—®é¢˜åˆ†è§£",
                border_style="yellow"
            ))
        
        if analysis.search_variants:
            console.print(Panel(
                "\n".join([f"â€¢ {v}" for v in analysis.search_variants]),
                title="ğŸ” æœç´¢å˜ä½“",
                border_style="cyan"
            ))
    
    def generate_follow_up_queries(self, original_query: str, 
                                  search_results: List[Dict[str, Any]], 
                                  current_knowledge: str) -> List[str]:
        """
        åŸºäºæœç´¢ç»“æœç”Ÿæˆåç»­æŸ¥è¯¢
        ç”¨äºå¤šè·³æœç´¢
        """
        
        console.print(Panel(
            "[bold blue]ğŸ§  ç”Ÿæˆåç»­æŸ¥è¯¢[/bold blue]",
            title="å¤šè·³æœç´¢",
            border_style="blue"
        ))
        
        # æ„å»ºåç»­æŸ¥è¯¢ç”Ÿæˆæç¤ºè¯
        follow_up_prompt = f"""
åŸºäºåŸå§‹æŸ¥è¯¢å’Œå½“å‰æœç´¢ç»“æœï¼Œç”Ÿæˆ2-3ä¸ªæœ‰é’ˆå¯¹æ€§çš„åç»­æœç´¢æŸ¥è¯¢ã€‚

åŸå§‹æŸ¥è¯¢: "{original_query}"

å½“å‰å·²çŸ¥ä¿¡æ¯:
{current_knowledge}

æœ€è¿‘æœç´¢ç»“æœæ‘˜è¦:
{self._summarize_search_results(search_results)}

è¯·ç”Ÿæˆ2-3ä¸ªåç»­æœç´¢æŸ¥è¯¢ï¼Œç”¨äºæ·±å…¥æ¢ç´¢ç›¸å…³ä¿¡æ¯ã€‚è¦æ±‚ï¼š
1. æ¯ä¸ªæŸ¥è¯¢åº”è¯¥æ¢ç´¢ä¸åŒçš„è§’åº¦æˆ–ç»†èŠ‚
2. æŸ¥è¯¢åº”è¯¥åŸºäºå·²æœ‰ä¿¡æ¯ï¼Œä½†å¯»æ±‚æ›´æ·±å±‚çš„æ´å¯Ÿ
3. é¿å…é‡å¤å·²ç»å……åˆ†å›ç­”çš„å†…å®¹
4. è¿”å›JSONæ ¼å¼: {{"follow_up_queries": ["æŸ¥è¯¢1", "æŸ¥è¯¢2", "æŸ¥è¯¢3"]}}
"""
        
        response = self.deepseek_client.chat_completion(
            messages=[{"role": "user", "content": follow_up_prompt}],
            stream=False,
            temperature=0.4
        )
        
        if "error" in response:
            # å¦‚æœAIç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨è§„åˆ™ç”Ÿæˆ
            return self._generate_rule_based_follow_ups(original_query, search_results)
        
        try:
            # æ¸…ç†å“åº”å†…å®¹ï¼Œç§»é™¤å¯èƒ½çš„markdownæ ¼å¼
            content = response["content"].strip()
            if content.startswith("```json"):
                content = content[7:]  # ç§»é™¤å¼€å¤´çš„ ```json
            if content.endswith("```"):
                content = content[:-3]  # ç§»é™¤ç»“å°¾çš„ ```
            content = content.strip()
            
            follow_up_data = json.loads(content)
            follow_up_queries = follow_up_data.get("follow_up_queries", [])
            
            console.print(Panel(
                "\n".join([f"â€¢ {q}" for q in follow_up_queries]),
                title="ğŸ¯ åç»­æŸ¥è¯¢",
                border_style="green"
            ))
            
            return follow_up_queries[:3]  # æœ€å¤šè¿”å›3ä¸ª
            
        except (json.JSONDecodeError, KeyError):
            return self._generate_rule_based_follow_ups(original_query, search_results)
    
    def _summarize_search_results(self, search_results: List[Dict[str, Any]]) -> str:
        """æ€»ç»“æœç´¢ç»“æœ"""
        summaries = []
        for result in search_results[:3]:  # åªå–å‰3ä¸ªç»“æœ
            summaries.append(f"- {result.get('title', '')}: {result.get('content', '')[:200]}...")
        return "\n".join(summaries)
    
    def _generate_rule_based_follow_ups(self, original_query: str, 
                                      search_results: List[Dict[str, Any]]) -> List[str]:
        """åŸºäºè§„åˆ™ç”Ÿæˆåç»­æŸ¥è¯¢ï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰"""
        
        follow_ups = [
            f"{original_query} å®é™…åº”ç”¨æ¡ˆä¾‹",
            f"{original_query} æœ€æ–°è¿›å±•",
            f"{original_query} ç›¸å…³æŠ€æœ¯å¯¹æ¯”"
        ]
        
        return follow_ups[:2]  # è¿”å›å‰2ä¸ª