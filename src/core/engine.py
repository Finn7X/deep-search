"""
æ·±åº¦æœç´¢å¼•æ“æ ¸å¿ƒ
æ•´åˆæ‰€æœ‰ç»„ä»¶ï¼Œæä¾›å®Œæ•´çš„æ·±åº¦æœç´¢åŠŸèƒ½
"""

import json
from typing import Dict, Any, Optional, List
from datetime import datetime
from rich.console import Console
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeElapsedColumn
from rich.table import Table
from rich.live import Live

from .config import Config
from ..search.tavily_search import TavilySearcher
from ..clients.deepseek_client import DeepSeekClient
from ..agents.query_analyzer import QueryAnalyzer, QueryAnalysis
from ..search.planner import SearchPlanner, SearchPlan
from ..agents.react_agent import ReActAgent

console = Console()

class DeepSearchEngine:
    """
    æ·±åº¦æœç´¢å¼•æ“ - æ•´åˆæ‰€æœ‰ç»„ä»¶çš„æ ¸å¿ƒç±»
    å®ç°çœŸæ­£çš„Deep SearchåŠŸèƒ½ï¼šæŸ¥è¯¢æ”¹å†™ã€åŠ¨æ€æœç´¢ã€å¤šè½®ReAct
    """
    
    def __init__(self, config: Config):
        self.config = config
        
        # åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
        self.tavily_searcher = TavilySearcher(config.tavily_api_key, config.max_search_results)
        self.deepseek_client = DeepSeekClient(
            config.deepseek_api_key, 
            config.deepseek_base_url, 
            config.deepseek_model
        )
        
        # åˆå§‹åŒ–AIç»„ä»¶
        self.query_analyzer = QueryAnalyzer(self.deepseek_client)
        self.search_planner = SearchPlanner(self.deepseek_client)
        self.react_agent = ReActAgent(self.deepseek_client, self.tavily_searcher)
        
        # æœç´¢ç»Ÿè®¡
        self.session_stats = {
            "total_queries": 0,
            "total_search_rounds": 0,
            "total_search_results": 0,
            "total_ai_calls": 0,
            "session_start": datetime.now().isoformat()
        }
        
        # ä¼šè¯å†å²
        self.session_history = []
    
    def deep_search(self, query: str, user_preferences: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´çš„æ·±åº¦æœç´¢æµç¨‹
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            user_preferences: ç”¨æˆ·åå¥½è®¾ç½®ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            å®Œæ•´çš„æ·±åº¦æœç´¢ç»“æœ
        """
        search_start_time = datetime.now()
        
        console.print(Panel(
            f"[bold magenta]ğŸš€ å¯åŠ¨Deep Searchå¼•æ“[/bold magenta]\n"
            f"[cyan]æŸ¥è¯¢:[/cyan] {query}\n"
            f"[cyan]å¼€å§‹æ—¶é—´:[/cyan] {search_start_time.strftime('%Y-%m-%d %H:%M:%S')}",
            title="Deep Search Engine",
            border_style="magenta"
        ))
        
        try:
            # ç¬¬ä¸€é˜¶æ®µï¼šæŸ¥è¯¢åˆ†æ
            console.print("\\n" + "="*60)
            console.print("[bold blue]ğŸ“‹ ç¬¬ä¸€é˜¶æ®µï¼šæ™ºèƒ½æŸ¥è¯¢åˆ†æ[/bold blue]")
            console.print("="*60)
            
            query_analysis = self.query_analyzer.analyze_query(query)
            
            # ç¬¬äºŒé˜¶æ®µï¼šæœç´¢è§„åˆ’
            console.print("\\n" + "="*60) 
            console.print("[bold yellow]ğŸ¯ ç¬¬äºŒé˜¶æ®µï¼šåŠ¨æ€æœç´¢è§„åˆ’[/bold yellow]")
            console.print("="*60)
            
            search_plan = self.search_planner.create_search_plan(query_analysis)
            
            # ç¬¬ä¸‰é˜¶æ®µï¼šReActæ·±åº¦æœç´¢
            console.print("\\n" + "="*60)
            console.print("[bold green]ğŸ¤– ç¬¬ä¸‰é˜¶æ®µï¼šReActæ™ºèƒ½æœç´¢[/bold green]")
            console.print("="*60)
            
            react_results = self.react_agent.execute_deep_search(query, query_analysis, search_plan)
            
            # ç¬¬å››é˜¶æ®µï¼šç»“æœæ•´åˆå’Œä¼˜åŒ–
            console.print("\\n" + "="*60)
            console.print("[bold purple]ğŸ“Š ç¬¬å››é˜¶æ®µï¼šç»“æœæ•´åˆåˆ†æ[/bold purple]")
            console.print("="*60)
            
            final_results = self._integrate_and_optimize_results(
                query, query_analysis, search_plan, react_results, search_start_time
            )
            
            # æ›´æ–°ä¼šè¯ç»Ÿè®¡
            self._update_session_stats(final_results)
            
            # è®°å½•åˆ°ä¼šè¯å†å²
            self.session_history.append(final_results)
            
            # æ˜¾ç¤ºæœ€ç»ˆæ‘˜è¦
            self._display_final_summary(final_results)
            
            return final_results
            
        except Exception as e:
            error_msg = f"Deep Searchæ‰§è¡Œå¤±è´¥: {str(e)}"
            console.print(f"[bold red]âŒ {error_msg}[/bold red]")
            
            return {
                "query": query,
                "error": error_msg,
                "timestamp": datetime.now().isoformat(),
                "success": False
            }
    
    def _integrate_and_optimize_results(self, query: str, query_analysis: QueryAnalysis, 
                                      search_plan: SearchPlan, react_results: Dict[str, Any],
                                      start_time: datetime) -> Dict[str, Any]:
        """
        æ•´åˆå’Œä¼˜åŒ–æœç´¢ç»“æœ
        """
        console.print(Panel(
            "[bold purple]ğŸ”— æ•´åˆæ‰€æœ‰æœç´¢ç»“æœ[/bold purple]",
            title="ç»“æœæ•´åˆ",
            border_style="purple"
        ))
        
        end_time = datetime.now()
        total_duration = (end_time - start_time).total_seconds()
        
        # æ”¶é›†æ‰€æœ‰æœç´¢ç»“æœ
        all_search_results = react_results.get("search_results", [])
        
        # ç»“æœå»é‡å’Œè´¨é‡è¿‡æ»¤
        filtered_results = self._filter_and_deduplicate_results(all_search_results)
        
        # ç”Ÿæˆå¢å¼ºçš„AIå›ç­”
        enhanced_answer = self._generate_enhanced_answer(
            query, query_analysis, filtered_results, react_results
        )
        
        # ç”Ÿæˆæœç´¢æ´å¯Ÿ
        search_insights = self._generate_search_insights(query_analysis, search_plan, react_results)
        
        # æ„å»ºæœ€ç»ˆç»“æœ
        final_results = {
            "query": query,
            "success": True,
            "timestamp": end_time.isoformat(),
            "total_duration_seconds": total_duration,
            
            # æ ¸å¿ƒç»“æœ
            "answer": enhanced_answer,
            "search_results": filtered_results,
            "total_results_found": len(all_search_results),
            "high_quality_results": len(filtered_results),
            
            # åˆ†æç»“æœ
            "query_analysis": {
                "complexity": query_analysis.complexity.value,
                "main_concepts": query_analysis.main_concepts,
                "requires_multi_hop": query_analysis.requires_multi_hop,
                "estimated_vs_actual_rounds": {
                    "estimated": query_analysis.estimated_search_rounds,
                    "actual": react_results.get("total_search_rounds", 0)
                }
            },
            
            # æœç´¢è¿‡ç¨‹
            "search_process": {
                "strategy": search_plan.strategy.value,
                "total_search_rounds": react_results.get("total_search_rounds", 0),
                "react_actions": react_results.get("execution_details", {}).get("actions", 0),
                "react_reflections": react_results.get("execution_details", {}).get("reflections", 0)
            },
            
            # æ·±åº¦æ´å¯Ÿ
            "insights": search_insights,
            
            # å…ƒæ•°æ®
            "metadata": {
                "search_engine_version": "2.0",
                "query_analyzer_used": True,
                "search_planner_used": True,
                "react_agent_used": True,
                "ai_model": self.config.deepseek_model
            }
        }
        
        return final_results
    
    def _filter_and_deduplicate_results(self, search_results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        è¿‡æ»¤å’Œå»é‡æœç´¢ç»“æœ
        """
        console.print(Panel(
            f"[cyan]ğŸ“ è¿‡æ»¤å’Œå»é‡æœç´¢ç»“æœ[/cyan]\\nåŸå§‹ç»“æœ: {len(search_results)} æ¡",
            title="ç»“æœå¤„ç†",
            border_style="cyan"
        ))
        
        if not search_results:
            return []
        
        # å»é‡ï¼ˆåŸºäºURLï¼‰
        seen_urls = set()
        unique_results = []
        
        for result in search_results:
            url = result.get("url", "")
            if url and url not in seen_urls:
                seen_urls.add(url)
                unique_results.append(result)
        
        # è´¨é‡è¿‡æ»¤ï¼ˆä¿ç•™è¯„åˆ†è¾ƒé«˜çš„ç»“æœï¼‰
        quality_threshold = 0.6
        high_quality_results = [
            result for result in unique_results 
            if result.get("score", 0) >= quality_threshold
        ]
        
        # å¦‚æœé«˜è´¨é‡ç»“æœå¤ªå°‘ï¼Œé™ä½æ ‡å‡†
        if len(high_quality_results) < 3:
            quality_threshold = 0.4
            high_quality_results = [
                result for result in unique_results 
                if result.get("score", 0) >= quality_threshold
            ]
        
        # æŒ‰è¯„åˆ†æ’åºï¼Œå–å‰15ä¸ª
        sorted_results = sorted(high_quality_results, key=lambda x: x.get("score", 0), reverse=True)
        final_results = sorted_results[:15]
        
        console.print(Panel(
            f"[green]âœ… ç»“æœå¤„ç†å®Œæˆ[/green]\\n"
            f"å»é‡å: {len(unique_results)} æ¡\\n"
            f"é«˜è´¨é‡: {len(high_quality_results)} æ¡\\n"
            f"æœ€ç»ˆä¿ç•™: {len(final_results)} æ¡",
            title="å¤„ç†ç»“æœ",
            border_style="green"
        ))
        
        return final_results
    
    def _generate_enhanced_answer(self, query: str, query_analysis: QueryAnalysis, 
                                filtered_results: List[Dict[str, Any]], 
                                react_results: Dict[str, Any]) -> str:
        """
        ç”Ÿæˆå¢å¼ºçš„AIå›ç­”
        """
        console.print(Panel(
            "[bold blue]ğŸ¤– ç”Ÿæˆå¢å¼ºAIå›ç­”[/bold blue]",
            title="AIå›ç­”ç”Ÿæˆ",
            border_style="blue"
        ))
        
        # æ„å»ºå¢å¼ºçš„ä¸Šä¸‹æ–‡
        enhanced_context = self._build_enhanced_context(
            query, query_analysis, filtered_results, react_results
        )
        
        # ç”Ÿæˆå›ç­”
        enhanced_prompt = f"""
ä½œä¸ºä¸€ä¸ªä¸“ä¸šçš„æ·±åº¦æœç´¢åˆ†æå¸ˆï¼Œè¯·åŸºäºä»¥ä¸‹å®Œæ•´çš„æœç´¢åˆ†æè¿‡ç¨‹å’Œç»“æœï¼Œæä¾›ä¸€ä¸ªå…¨é¢ã€å‡†ç¡®ã€æ·±å…¥çš„å›ç­”ã€‚

{enhanced_context}

è¯·æä¾›ä¸€ä¸ªç»“æ„åŒ–çš„è¯¦ç»†å›ç­”ï¼Œè¦æ±‚ï¼š
1. ç›´æ¥å‡†ç¡®åœ°å›ç­”ç”¨æˆ·é—®é¢˜
2. æä¾›å…·ä½“çš„äº‹å®ã€æ•°æ®å’Œä¾‹å­
3. å¼•ç”¨å¯é çš„ä¿¡æ¯æ¥æº
4. åˆ†æä¸åŒè§‚ç‚¹å’Œè§’åº¦
5. æŒ‡å‡ºä»»ä½•ä¸ç¡®å®šæ€§æˆ–é™åˆ¶
6. å¦‚æœæ˜¯å¤æ‚é—®é¢˜ï¼Œæä¾›åˆ†å±‚æ¬¡çš„åˆ†æ
7. æ€»ç»“å…³é”®è¦ç‚¹å’Œå®ç”¨å»ºè®®

å›ç­”åº”è¯¥ä¸“ä¸šã€å®¢è§‚ã€æœ‰æ·±åº¦ï¼Œä½“ç°å‡ºå¤šè½®æ·±åº¦æœç´¢çš„ä»·å€¼ã€‚
"""
        
        response = self.deepseek_client.chat_completion(
            messages=[{"role": "user", "content": enhanced_prompt}],
            stream=True,
            temperature=0.2
        )
        
        if "error" in response:
            return f"åŸºäº{len(filtered_results)}æ¡é«˜è´¨é‡æœç´¢ç»“æœçš„åˆ†æï¼Œæ— æ³•ç”ŸæˆAIå›ç­”ã€‚è¯·æŸ¥çœ‹è¯¦ç»†æœç´¢ç»“æœã€‚"
        
        return response.get("content", "å›ç­”ç”Ÿæˆå¤±è´¥")
    
    def _build_enhanced_context(self, query: str, query_analysis: QueryAnalysis,
                              filtered_results: List[Dict[str, Any]], 
                              react_results: Dict[str, Any]) -> str:
        """
        æ„å»ºå¢å¼ºçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        """
        context_parts = [
            f"ç”¨æˆ·æŸ¥è¯¢: {query}",
            "",
            f"æŸ¥è¯¢å¤æ‚åº¦åˆ†æ: {query_analysis.complexity.value}",
            f"ä¸»è¦æ¦‚å¿µ: {', '.join(query_analysis.main_concepts)}",
            f"æ˜¯å¦éœ€è¦å¤šè·³æœç´¢: {'æ˜¯' if query_analysis.requires_multi_hop else 'å¦'}",
            "",
            f"æœç´¢è¿‡ç¨‹æ¦‚è¿°:",
            f"- æ€»æœç´¢è½®æ¬¡: {react_results.get('total_search_rounds', 0)}",
            f"- ReActè¡ŒåŠ¨æ¬¡æ•°: {react_results.get('execution_details', {}).get('actions', 0)}",
            f"- æœ€ç»ˆæœç´¢è¿›åº¦: {react_results.get('execution_details', {}).get('final_progress', 0):.1%}",
            "",
            "é«˜è´¨é‡æœç´¢ç»“æœ:"
        ]
        
        # æ·»åŠ æœç´¢ç»“æœ
        for i, result in enumerate(filtered_results[:10], 1):
            context_parts.extend([
                f"",
                f"ç»“æœ {i}:",
                f"æ ‡é¢˜: {result.get('title', '')}",
                f"æ¥æº: {result.get('url', '')}",
                f"ç›¸å…³æ€§: {result.get('score', 0):.2f}",
                f"å†…å®¹: {result.get('content', '')[:400]}..."
            ])
        
        # æ·»åŠ ReActç§¯ç´¯çš„çŸ¥è¯†
        accumulated_knowledge = react_results.get("accumulated_knowledge", "")
        if accumulated_knowledge:
            context_parts.extend([
                "",
                "ReActä»£ç†ç§¯ç´¯çš„æ·±åº¦çŸ¥è¯†:",
                accumulated_knowledge[:2000] + "..." if len(accumulated_knowledge) > 2000 else accumulated_knowledge
            ])
        
        return "\\n".join(context_parts)
    
    def _generate_search_insights(self, query_analysis: QueryAnalysis, 
                                search_plan: SearchPlan, 
                                react_results: Dict[str, Any]) -> Dict[str, Any]:
        """
        ç”Ÿæˆæœç´¢è¿‡ç¨‹æ´å¯Ÿ
        """
        insights = {
            "query_complexity_assessment": {
                "identified_complexity": query_analysis.complexity.value,
                "required_multi_hop": query_analysis.requires_multi_hop,
                "estimated_rounds": query_analysis.estimated_search_rounds,
                "actual_rounds": react_results.get("total_search_rounds", 0)
            },
            
            "search_strategy_effectiveness": {
                "planned_strategy": search_plan.strategy.value,
                "total_planned_rounds": len(search_plan.search_rounds),
                "actual_react_actions": react_results.get("execution_details", {}).get("actions", 0),
                "final_progress_achieved": react_results.get("execution_details", {}).get("final_progress", 0)
            },
            
            "information_discovery": {
                "total_sources_found": len(react_results.get("search_results", [])),
                "unique_domains": len(set(r.get("url", "").split("/")[2] for r in react_results.get("search_results", []) if r.get("url"))),
                "average_relevance_score": self._calculate_average_score(react_results.get("search_results", []))
            },
            
            "react_agent_performance": {
                "reasoning_cycles": react_results.get("execution_details", {}).get("reflections", 0),
                "adaptive_queries_generated": self._count_adaptive_queries(react_results),
                "knowledge_accumulation_size": len(react_results.get("accumulated_knowledge", ""))
            }
        }
        
        return insights
    
    def _calculate_average_score(self, results: List[Dict[str, Any]]) -> float:
        """è®¡ç®—å¹³å‡ç›¸å…³æ€§è¯„åˆ†"""
        if not results:
            return 0.0
        
        scores = [r.get("score", 0) for r in results if "score" in r]
        return sum(scores) / len(scores) if scores else 0.0
    
    def _count_adaptive_queries(self, react_results: Dict[str, Any]) -> int:
        """ç»Ÿè®¡è‡ªé€‚åº”æŸ¥è¯¢æ•°é‡"""
        # ç®€å•ç»Ÿè®¡ - å®é™…å®ç°ä¸­å¯ä»¥æ›´è¯¦ç»†åœ°è¿½è¸ª
        return react_results.get("total_search_rounds", 0) * 2
    
    def _update_session_stats(self, results: Dict[str, Any]):
        """æ›´æ–°ä¼šè¯ç»Ÿè®¡"""
        self.session_stats["total_queries"] += 1
        self.session_stats["total_search_rounds"] += results.get("search_process", {}).get("total_search_rounds", 0)
        self.session_stats["total_search_results"] += results.get("total_results_found", 0)
        self.session_stats["total_ai_calls"] += results.get("search_process", {}).get("react_actions", 0)
    
    def _display_final_summary(self, results: Dict[str, Any]):
        """æ˜¾ç¤ºæœ€ç»ˆæ‘˜è¦"""
        
        # åˆ›å»ºæ‘˜è¦è¡¨æ ¼
        table = Table(title="ğŸ¯ Deep Search å®Œæˆæ‘˜è¦", style="cyan")
        table.add_column("æŒ‡æ ‡", style="yellow")
        table.add_column("ç»“æœ", style="green")
        
        table.add_row("æŸ¥è¯¢å¤æ‚åº¦", results["query_analysis"]["complexity"])
        table.add_row("æœç´¢ç­–ç•¥", results["search_process"]["strategy"])
        table.add_row("æœç´¢è½®æ¬¡", str(results["search_process"]["total_search_rounds"]))
        table.add_row("ReActè¡ŒåŠ¨", str(results["search_process"]["react_actions"]))
        table.add_row("æ‰¾åˆ°ç»“æœ", f"{results['total_results_found']} æ¡")
        table.add_row("é«˜è´¨é‡ç»“æœ", f"{results['high_quality_results']} æ¡")
        table.add_row("æ€»è€—æ—¶", f"{results['total_duration_seconds']:.1f} ç§’")
        
        console.print(table)
        
        # æ˜¾ç¤ºæ´å¯Ÿæ‘˜è¦
        insights = results["insights"]
        console.print(Panel(
            f"[bold blue]ğŸ“Š æœç´¢æ´å¯Ÿ[/bold blue]\\n"
            f"[cyan]ä¿¡æ¯å‘ç°:[/cyan] æ¥æº {insights['information_discovery']['unique_domains']} ä¸ªåŸŸå\\n"
            f"[cyan]å¹³å‡ç›¸å…³æ€§:[/cyan] {insights['information_discovery']['average_relevance_score']:.2f}\\n"
            f"[cyan]ReActæ€§èƒ½:[/cyan] {insights['react_agent_performance']['reasoning_cycles']} æ¬¡æ¨ç†å¾ªç¯\\n"
            f"[cyan]çŸ¥è¯†ç§¯ç´¯:[/cyan] {insights['react_agent_performance']['knowledge_accumulation_size']} å­—ç¬¦",
            title="æ™ºèƒ½æ´å¯Ÿ",
            border_style="blue"
        ))
    
    def get_session_stats(self) -> Dict[str, Any]:
        """è·å–ä¼šè¯ç»Ÿè®¡"""
        return self.session_stats.copy()
    
    def get_session_history(self) -> List[Dict[str, Any]]:
        """è·å–ä¼šè¯å†å²"""
        return self.session_history.copy()
    
    def clear_session(self):
        """æ¸…ç©ºä¼šè¯"""
        self.session_history.clear()
        self.deepseek_client.clear_conversation()
        console.print("[yellow]ğŸ”„ Deep Searchä¼šè¯å·²æ¸…ç©º[/yellow]")