"""
æœç´¢è§„åˆ’å™¨
åŸºäºæŸ¥è¯¢åˆ†æç»“æœåŠ¨æ€ç¡®å®šæœç´¢ç­–ç•¥å’Œå‚æ•°
"""

from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import json
from rich.console import Console
from rich.panel import Panel
from rich.table import Table

from query_analyzer import QueryAnalysis, QueryComplexity

console = Console()

class SearchStrategy(Enum):
    DIRECT = "direct"                   # ç›´æ¥æœç´¢
    MULTI_ANGLE = "multi_angle"         # å¤šè§’åº¦æœç´¢
    SEQUENTIAL = "sequential"           # åºåˆ—æœç´¢
    PARALLEL_DEEP = "parallel_deep"     # å¹¶è¡Œæ·±åº¦æœç´¢

@dataclass
class SearchPlan:
    strategy: SearchStrategy
    search_rounds: List['SearchRound']
    total_estimated_time: float
    priority_domains: List[str]
    fallback_queries: List[str]

@dataclass
class SearchRound:
    round_number: int
    queries: List[str]
    search_depth: str  # "basic" or "advanced"
    max_results: int
    include_domains: Optional[List[str]]
    exclude_domains: Optional[List[str]]
    timeout_seconds: int
    depends_on_previous: bool  # æ˜¯å¦ä¾èµ–å‰ä¸€è½®çš„ç»“æœ

class SearchPlanner:
    def __init__(self, deepseek_client):
        self.deepseek_client = deepseek_client
        
        # é»˜è®¤æœç´¢é…ç½®
        self.default_config = {
            "max_results_simple": 5,
            "max_results_moderate": 8,
            "max_results_complex": 12,
            "max_results_multi_hop": 15,
            "timeout_basic": 30,
            "timeout_advanced": 60,
            "max_parallel_searches": 3
        }
        
        # åŸŸåä¼˜å…ˆçº§é…ç½®
        self.domain_priorities = {
            "academic": ["arxiv.org", "scholar.google.com", "pubmed.ncbi.nlm.nih.gov", "ieee.org"],
            "technical": ["github.com", "stackoverflow.com", "docs.python.org", "developer.mozilla.org"],
            "news": ["reuters.com", "bbc.com", "cnn.com", "bloomberg.com"],
            "general": ["wikipedia.org", "britannica.com", "reddit.com"],
            "business": ["harvard.edu", "mit.edu", "stanford.edu", "fortune.com"]
        }
    
    def create_search_plan(self, query_analysis: QueryAnalysis, context: Optional[str] = None) -> SearchPlan:
        """
        åŸºäºæŸ¥è¯¢åˆ†æåˆ›å»ºæœç´¢è®¡åˆ’
        """
        console.print(Panel(
            f"[bold blue]ğŸ“‹ åˆ›å»ºæœç´¢è®¡åˆ’[/bold blue]\n"
            f"[cyan]æŸ¥è¯¢å¤æ‚åº¦:[/cyan] {query_analysis.complexity.value}\n"
            f"[cyan]é¢„ä¼°æœç´¢è½®æ¬¡:[/cyan] {query_analysis.estimated_search_rounds}",
            title="æœç´¢è§„åˆ’",
            border_style="blue"
        ))
        
        # ç¡®å®šæœç´¢ç­–ç•¥
        strategy = self._determine_strategy(query_analysis)
        
        # åˆ›å»ºæœç´¢è½®æ¬¡
        search_rounds = self._create_search_rounds(query_analysis, strategy, context)
        
        # è®¡ç®—é¢„ä¼°æ—¶é—´
        estimated_time = self._calculate_estimated_time(search_rounds)
        
        # ç¡®å®šä¼˜å…ˆåŸŸå
        priority_domains = self._select_priority_domains(query_analysis)
        
        # ç”Ÿæˆå¤‡é€‰æŸ¥è¯¢
        fallback_queries = self._generate_fallback_queries(query_analysis)
        
        search_plan = SearchPlan(
            strategy=strategy,
            search_rounds=search_rounds,
            total_estimated_time=estimated_time,
            priority_domains=priority_domains,
            fallback_queries=fallback_queries
        )
        
        self._log_search_plan(search_plan)
        return search_plan
    
    def _determine_strategy(self, query_analysis: QueryAnalysis) -> SearchStrategy:
        """ç¡®å®šæœç´¢ç­–ç•¥"""
        
        if query_analysis.complexity == QueryComplexity.SIMPLE:
            return SearchStrategy.DIRECT
        elif query_analysis.complexity == QueryComplexity.MODERATE:
            return SearchStrategy.MULTI_ANGLE
        elif query_analysis.complexity == QueryComplexity.COMPLEX:
            return SearchStrategy.SEQUENTIAL
        else:  # MULTI_HOP
            return SearchStrategy.PARALLEL_DEEP
    
    def _create_search_rounds(self, query_analysis: QueryAnalysis, 
                            strategy: SearchStrategy, context: Optional[str]) -> List[SearchRound]:
        """åˆ›å»ºæœç´¢è½®æ¬¡"""
        
        rounds = []
        
        if strategy == SearchStrategy.DIRECT:
            # ç›´æ¥æœç´¢ç­–ç•¥ - å•è½®æœç´¢
            rounds.append(SearchRound(
                round_number=1,
                queries=[query_analysis.original_query],
                search_depth="basic",
                max_results=self.default_config["max_results_simple"],
                include_domains=query_analysis.domain_hints[:3] if query_analysis.domain_hints else None,
                exclude_domains=None,
                timeout_seconds=self.default_config["timeout_basic"],
                depends_on_previous=False
            ))
            
        elif strategy == SearchStrategy.MULTI_ANGLE:
            # å¤šè§’åº¦æœç´¢ - ä½¿ç”¨æœç´¢å˜ä½“
            rounds.append(SearchRound(
                round_number=1,
                queries=query_analysis.search_variants[:3],
                search_depth="advanced",
                max_results=self.default_config["max_results_moderate"],
                include_domains=query_analysis.domain_hints[:3] if query_analysis.domain_hints else None,
                exclude_domains=None,
                timeout_seconds=self.default_config["timeout_advanced"],
                depends_on_previous=False
            ))
            
        elif strategy == SearchStrategy.SEQUENTIAL:
            # åºåˆ—æœç´¢ - å…ˆæ¦‚è¿°å†æ·±å…¥
            rounds.append(SearchRound(
                round_number=1,
                queries=[query_analysis.original_query, f"{query_analysis.original_query} æ¦‚è¿°"],
                search_depth="advanced",
                max_results=self.default_config["max_results_complex"],
                include_domains=None,
                exclude_domains=["reddit.com", "twitter.com"],  # æ’é™¤ç¤¾äº¤åª’ä½“
                timeout_seconds=self.default_config["timeout_advanced"],
                depends_on_previous=False
            ))
            
            # ç¬¬äºŒè½®åŸºäºå­é—®é¢˜
            if query_analysis.sub_questions:
                rounds.append(SearchRound(
                    round_number=2,
                    queries=query_analysis.sub_questions[:2],
                    search_depth="advanced",
                    max_results=self.default_config["max_results_complex"],
                    include_domains=query_analysis.domain_hints[:2] if query_analysis.domain_hints else None,
                    exclude_domains=None,
                    timeout_seconds=self.default_config["timeout_advanced"],
                    depends_on_previous=True
                ))
                
        else:  # PARALLEL_DEEP
            # å¹¶è¡Œæ·±åº¦æœç´¢ - å¤šä¸ªç»´åº¦åŒæ—¶æ¢ç´¢
            rounds.append(SearchRound(
                round_number=1,
                queries=[query_analysis.original_query] + query_analysis.search_variants[:2],
                search_depth="advanced",
                max_results=self.default_config["max_results_multi_hop"],
                include_domains=None,
                exclude_domains=None,
                timeout_seconds=self.default_config["timeout_advanced"],
                depends_on_previous=False
            ))
            
            # åŸºäºå­é—®é¢˜çš„æ·±å…¥æœç´¢
            if query_analysis.sub_questions:
                rounds.append(SearchRound(
                    round_number=2,
                    queries=query_analysis.sub_questions,
                    search_depth="advanced",
                    max_results=self.default_config["max_results_multi_hop"],
                    include_domains=query_analysis.domain_hints if query_analysis.domain_hints else None,
                    exclude_domains=None,
                    timeout_seconds=self.default_config["timeout_advanced"],
                    depends_on_previous=True
                ))
                
                # å¯èƒ½çš„ç¬¬ä¸‰è½® - ä¸“å®¶çº§æœç´¢
                rounds.append(SearchRound(
                    round_number=3,
                    queries=[],  # å°†åœ¨æ‰§è¡Œæ—¶åŸºäºå‰ä¸¤è½®ç»“æœåŠ¨æ€ç”Ÿæˆ
                    search_depth="advanced",
                    max_results=10,
                    include_domains=query_analysis.domain_hints[:3] if query_analysis.domain_hints else None,
                    exclude_domains=["reddit.com", "twitter.com", "facebook.com"],
                    timeout_seconds=self.default_config["timeout_advanced"],
                    depends_on_previous=True
                ))
        
        return rounds
    
    def _select_priority_domains(self, query_analysis: QueryAnalysis) -> List[str]:
        """é€‰æ‹©ä¼˜å…ˆæœç´¢åŸŸå"""
        
        priority_domains = []
        
        # é¦–å…ˆä½¿ç”¨æŸ¥è¯¢åˆ†æä¸­çš„åŸŸåæç¤º
        if query_analysis.domain_hints:
            priority_domains.extend(query_analysis.domain_hints)
        
        # åŸºäºä¸»è¦æ¦‚å¿µæ™ºèƒ½é€‰æ‹©åŸŸå
        main_concepts_str = " ".join(query_analysis.main_concepts).lower()
        
        # å­¦æœ¯ç›¸å…³
        if any(term in main_concepts_str for term in ["ç ”ç©¶", "è®ºæ–‡", "å­¦æœ¯", "ç†è®º", "ç®—æ³•"]):
            priority_domains.extend(self.domain_priorities["academic"][:2])
        
        # æŠ€æœ¯ç›¸å…³
        if any(term in main_concepts_str for term in ["ç¼–ç¨‹", "ä»£ç ", "å¼€å‘", "API", "æ¡†æ¶"]):
            priority_domains.extend(self.domain_priorities["technical"][:2])
        
        # å•†ä¸šç›¸å…³
        if any(term in main_concepts_str for term in ["å•†ä¸š", "å¸‚åœº", "ç»æµ", "å…¬å¸", "æŠ•èµ„"]):
            priority_domains.extend(self.domain_priorities["business"][:2])
        
        # æ–°é—»ç›¸å…³
        if any(term in main_concepts_str for term in ["æ–°é—»", "æœ€æ–°", "å‘å±•", "è¶‹åŠ¿", "äº‹ä»¶"]):
            priority_domains.extend(self.domain_priorities["news"][:2])
        
        # å»é‡å¹¶é™åˆ¶æ•°é‡
        unique_domains = list(dict.fromkeys(priority_domains))  # ä¿æŒé¡ºåºçš„å»é‡
        return unique_domains[:5]  # æœ€å¤š5ä¸ªä¼˜å…ˆåŸŸå
    
    def _generate_fallback_queries(self, query_analysis: QueryAnalysis) -> List[str]:
        """ç”Ÿæˆå¤‡é€‰æŸ¥è¯¢ï¼ˆå½“ä¸»è¦æœç´¢å¤±è´¥æ—¶ä½¿ç”¨ï¼‰"""
        
        original = query_analysis.original_query
        fallbacks = [
            f"{original} åŸºç¡€çŸ¥è¯†",
            f"{original} ç®€ä»‹",
            f"ä»€ä¹ˆæ˜¯ {original}",
            f"{original} ç›¸å…³èµ„æ–™"
        ]
        
        return fallbacks[:3]
    
    def _calculate_estimated_time(self, search_rounds: List[SearchRound]) -> float:
        """è®¡ç®—é¢„ä¼°æœç´¢æ—¶é—´ï¼ˆç§’ï¼‰"""
        
        total_time = 0.0
        
        for round_info in search_rounds:
            # æ¯ä¸ªæŸ¥è¯¢çš„åŸºç¡€æ—¶é—´
            query_time = len(round_info.queries) * 5.0  # æ¯ä¸ªæŸ¥è¯¢5ç§’
            
            # æ ¹æ®æœç´¢æ·±åº¦è°ƒæ•´
            if round_info.search_depth == "advanced":
                query_time *= 1.5
            
            # æ ¹æ®ç»“æœæ•°é‡è°ƒæ•´
            result_factor = round_info.max_results / 10.0
            query_time *= result_factor
            
            total_time += query_time
        
        return total_time
    
    def _log_search_plan(self, search_plan: SearchPlan):
        """è®°å½•æœç´¢è®¡åˆ’"""
        
        console.print(Panel(
            f"[bold green]âœ… æœç´¢è®¡åˆ’åˆ›å»ºå®Œæˆ[/bold green]\n"
            f"[cyan]ç­–ç•¥:[/cyan] {search_plan.strategy.value}\n"
            f"[cyan]æœç´¢è½®æ¬¡:[/cyan] {len(search_plan.search_rounds)}\n"
            f"[cyan]é¢„ä¼°æ—¶é—´:[/cyan] {search_plan.total_estimated_time:.1f} ç§’\n"
            f"[cyan]ä¼˜å…ˆåŸŸå:[/cyan] {len(search_plan.priority_domains)} ä¸ª",
            title="æœç´¢è®¡åˆ’æ¦‚è§ˆ",
            border_style="green"
        ))
        
        # è¯¦ç»†æœç´¢è½®æ¬¡è¡¨æ ¼
        table = Table(title="ğŸ¯ æœç´¢è½®æ¬¡è¯¦æƒ…", style="cyan")
        table.add_column("è½®æ¬¡", style="yellow")
        table.add_column("æŸ¥è¯¢æ•°", style="green")
        table.add_column("æœç´¢æ·±åº¦", style="blue")
        table.add_column("æœ€å¤§ç»“æœ", style="magenta")
        table.add_column("ä¾èµ–å‰è½®", style="red")
        
        for round_info in search_plan.search_rounds:
            table.add_row(
                str(round_info.round_number),
                str(len(round_info.queries)),
                round_info.search_depth,
                str(round_info.max_results),
                "æ˜¯" if round_info.depends_on_previous else "å¦"
            )
        
        console.print(table)
        
        # æ˜¾ç¤ºä¼˜å…ˆåŸŸå
        if search_plan.priority_domains:
            console.print(Panel(
                "\n".join([f"â€¢ {domain}" for domain in search_plan.priority_domains]),
                title="ğŸ¯ ä¼˜å…ˆæœç´¢åŸŸå",
                border_style="yellow"
            ))
    
    def adapt_plan_based_on_results(self, search_plan: SearchPlan, 
                                   round_number: int, 
                                   search_results: List[Dict[str, Any]],
                                   current_knowledge: str) -> Optional[SearchRound]:
        """
        åŸºäºæœç´¢ç»“æœåŠ¨æ€è°ƒæ•´æœç´¢è®¡åˆ’
        """
        console.print(Panel(
            f"[bold blue]ğŸ”„ åŠ¨æ€è°ƒæ•´æœç´¢è®¡åˆ’[/bold blue]\n"
            f"[cyan]å½“å‰è½®æ¬¡:[/cyan] {round_number}\n"
            f"[cyan]æœç´¢ç»“æœæ•°:[/cyan] {len(search_results)}",
            title="è®¡åˆ’è°ƒæ•´",
            border_style="blue"
        ))
        
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰åç»­è½®æ¬¡
        next_round_number = round_number + 1
        next_round = None
        
        for round_info in search_plan.search_rounds:
            if round_info.round_number == next_round_number:
                next_round = round_info
                break
        
        if not next_round:
            return None
        
        # å¦‚æœä¸‹ä¸€è½®ä¾èµ–å½“å‰ç»“æœï¼ŒåŠ¨æ€ç”ŸæˆæŸ¥è¯¢
        if next_round.depends_on_previous and not next_round.queries:
            # ç”ŸæˆåŸºäºå½“å‰ç»“æœçš„æ–°æŸ¥è¯¢
            new_queries = self._generate_adaptive_queries(
                search_results, current_knowledge, next_round_number
            )
            next_round.queries = new_queries
        
        # åŸºäºç»“æœè´¨é‡è°ƒæ•´å‚æ•°
        if len(search_results) < 3:  # ç»“æœå¤ªå°‘
            next_round.max_results = min(next_round.max_results + 5, 20)
            next_round.exclude_domains = None  # ç§»é™¤åŸŸåé™åˆ¶
            console.print("[yellow]âš ï¸  ç»“æœè¾ƒå°‘ï¼Œå¢åŠ æœç´¢èŒƒå›´[/yellow]")
        
        return next_round
    
    def _generate_adaptive_queries(self, search_results: List[Dict[str, Any]], 
                                 current_knowledge: str, round_number: int) -> List[str]:
        """åŸºäºæœç´¢ç»“æœç”Ÿæˆè‡ªé€‚åº”æŸ¥è¯¢"""
        
        # æå–æœç´¢ç»“æœä¸­çš„å…³é”®ä¿¡æ¯
        key_terms = []
        for result in search_results[:3]:
            title = result.get("title", "")
            content = result.get("content", "")
            # ç®€å•çš„å…³é”®è¯æå–ï¼ˆå®é™…åº”ç”¨ä¸­å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„NLPæ–¹æ³•ï¼‰
            words = (title + " " + content).split()
            key_terms.extend([word for word in words if len(word) > 4][:5])
        
        # åŸºäºè½®æ¬¡ç”Ÿæˆä¸åŒç±»å‹çš„æŸ¥è¯¢
        if round_number == 2:
            # ç¬¬äºŒè½®ï¼šæ·±å…¥æ¢ç´¢
            queries = [
                f"{' '.join(key_terms[:3])} è¯¦ç»†åˆ†æ",
                f"{' '.join(key_terms[:2])} å®é™…åº”ç”¨",
            ]
        elif round_number == 3:
            # ç¬¬ä¸‰è½®ï¼šä¸“å®¶çº§æŸ¥è¯¢
            queries = [
                f"{' '.join(key_terms[:2])} æœ€æ–°ç ”ç©¶",
                f"{' '.join(key_terms[:3])} æŠ€æœ¯ç»†èŠ‚"
            ]
        else:
            # é»˜è®¤æŸ¥è¯¢
            queries = [f"{' '.join(key_terms[:2])} ç›¸å…³ä¿¡æ¯"]
        
        console.print(Panel(
            "\n".join([f"â€¢ {q}" for q in queries]),
            title=f"ğŸ¯ ç¬¬{round_number}è½®è‡ªé€‚åº”æŸ¥è¯¢",
            border_style="cyan"
        ))
        
        return queries[:2]  # æœ€å¤šè¿”å›2ä¸ªæŸ¥è¯¢